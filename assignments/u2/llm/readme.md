
```â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ğŸŒ¦ï¸ Dashboard Clima IoT + LLMâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                                      â”‚
â”‚   ğŸ“ˆ Temperatura (Â°C)         ğŸ’§ Humedad (%)                 ğŸŒ¬ï¸ Viento (km/h)        â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”‚
â”‚   30 â”¤      â•­â”€â”€â”€â•®             100 â”¤ â•­â•®                        40 â”¤      â•­â”€â•®         â”‚
â”‚   25 â”¤   â•­â”€â”€â•¯   â•°â”€â”€â•®           80 â”¤ â”‚â”‚ â•­â”€â”€â•®                    30 â”¤   â•­â”€â•¯ â•°â”€â•®       â”‚
â”‚   20 â”¤ â•­â”€â•¯        â•°â”€â•®          60 â”¤ â”‚â•°â”€â•¯  â•°â•®                   20 â”¤ â•­â”€â•¯     â•°â”€â•®     â”‚
â”‚   15 â”¤â•¯            â•°â”€           40 â”¤ â”‚      â•°â”€â”€â•®                10 â”¤â•¯         â•°â”€    â”‚
â”‚                                                                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ¤– Asistente LLM (Chat)                                                               â”‚
â”‚ Usuario: Â¿CÃ³mo estuvo el clima esta semana?                                           â”‚
â”‚                                                                                      â”‚
â”‚ LLM: La temperatura promedio fue de ğŸŒ¡ï¸ 22Â°C, con mÃ¡ximas de 29Â°C el jueves.          â”‚
â”‚      La humedad bajÃ³ ğŸ“‰ un 15% entre lunes y miÃ©rcoles. El viento se mantuvo estable. â”‚
â”‚                                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
````



## ğŸ“ŠğŸ”— **Dashboard con API de LLM**

Un **dashboard con API de LLM** no solo muestra datos de sensores o sistemas, sino que tambiÃ©n permite **interpretarlos, resumirlos y explicarlos** automÃ¡ticamente usando un **modelo de lenguaje grande (LLM)** como GPT.

---

### ğŸ”§ **Arquitectura tÃ­pica**

```
ğŸŒ¡ï¸ Sensores IoT / Sistemas
        â”‚
        â–¼
ğŸ“¨ Broker MQTT â†’ ğŸ—„ï¸ InfluxDB / Prometheus (almacenamiento de series temporales)
        â”‚
        â–¼
ğŸ“Š Grafana (dashboard interactivo con grÃ¡ficas y alertas)
        â”‚
        â–¼
ğŸ¤– API de LLM (ej. GPT, LLaMA, Claude)
        â”‚
        â””â”€â”€> ExplicaciÃ³n en lenguaje natural + respuestas a consultas
```

---

### ğŸš€ **CÃ³mo funciona en la prÃ¡ctica**

1. **Datos en tiempo real** llegan de sensores o sistemas a la base de datos (InfluxDB/Prometheus).
2. **Grafana** genera el dashboard visual (grÃ¡ficas de temperatura, consumo de CPU, etc.).
3. El **LLM se integra como API** dentro de Grafana o un servicio adicional:

   * ğŸ“ El usuario puede **preguntar en lenguaje natural**:

     > "Â¿CuÃ¡l fue la temperatura promedio esta semana?"
   * El **LLM interpreta la consulta**, genera una query (ej. en SQL o PromQL) hacia la base de datos.
   * Obtiene los datos y los **resume en lenguaje humano**.

---

### ğŸ’¡ **Ejemplos de uso**

* ğŸŒ¡ï¸ **IoT:** El LLM analiza los datos de humedad y temperatura y te dice:

  > "La humedad bajÃ³ un 12% en los Ãºltimos 3 dÃ­as, probablemente por el cambio de clima."
* ğŸ–¥ï¸ **Sistemas:** En lugar de leer mÃ©tricas tÃ©cnicas, puedes preguntar:

  > "Â¿Por quÃ© estÃ¡ lenta la aplicaciÃ³n?"
  > El LLM revisa datos de CPU, RAM y logs â†’ responde:
  > "El servidor alcanzÃ³ el 95% de CPU entre las 3 y 4 PM por exceso de peticiones."
* ğŸ§¾ **Reportes automÃ¡ticos:** El LLM genera un informe diario/semanal con texto narrativo y grÃ¡ficas incrustadas del dashboard.

---

### âš™ï¸ **TecnologÃ­as que pueden integrarse**

* **Grafana plugins**: usar paneles con chatbots conectados a APIs de LLM.
* **LangChain / LlamaIndex**: frameworks que convierten preguntas en queries hacia las BD de series temporales.
* **APIs de OpenAI, Anthropic, Meta (LLaMA), Mistral, etc.** para el motor LLM.

---

ğŸ‘‰ En resumen:
Un **dashboard con API de LLM** no solo muestra grÃ¡ficas, sino que **explica, responde y predice** con lenguaje natural, convirtiÃ©ndose en un **asistente inteligente de monitoreo**.


---

Â¡Excelente! ğŸ˜ƒ Entonces podemos armar una **prÃ¡ctica guiada para estudiantes de IngenierÃ­a en Sistemas** en el curso de **Sistemas Programables**, usando lo que ya saben (APIs como OpenWeatherMAP) y llevÃ¡ndolos a integrar un **dashboard + LLM**.

---

# ğŸ› ï¸ PrÃ¡ctica: Dashboard Inteligente con LLM y OpenWeatherMAP

**Objetivo:** Desarrollar un dashboard que muestre datos del clima en tiempo real (API OpenWeatherMAP), almacenarlos en una base de datos de series temporales, visualizarlos en Grafana y usar un LLM (ej. GPT API) para interpretar los resultados en lenguaje natural.

---

## ğŸ”— Flujo de la prÃ¡ctica

```text
ğŸŒ¦ï¸ OpenWeatherMAP API  â†’  ğŸ“¥ InfluxDB
                                  â”‚
                                  â–¼
                           ğŸ“Š Grafana
                                  â”‚
                                  â–¼
                           ğŸ¤– API de LLM
```

---

## ğŸ§© Etapas de desarrollo

### 1ï¸âƒ£ Captura de datos (API OpenWeatherMAP)

* Lenguaje sugerido: **Python** o **Node.js**.
* Los estudiantes ya saben obtener JSON de la API, ej:

  * Temperatura ğŸŒ¡ï¸
  * Humedad ğŸ’§
  * Velocidad del viento ğŸŒ¬ï¸

ğŸ‘‰ Guardar estos datos en **InfluxDB** como series temporales.

---

### 2ï¸âƒ£ VisualizaciÃ³n en Grafana

* Conectar Grafana a InfluxDB.
* Crear paneles bÃ¡sicos:

  * GrÃ¡fica de temperatura en las Ãºltimas 24h.
  * Humedad promedio por dÃ­a.
  * Mapa con la ciudad configurada.

---

### 3ï¸âƒ£ IntegraciÃ³n con un LLM

* Usar **OpenAI API** (o cualquier LLM disponible).
* Desarrollar un **mÃ³dulo intermedio en Python**:

  * El estudiante envÃ­a una pregunta en lenguaje natural (ej. *"Â¿CÃ³mo estuvo la temperatura esta semana?"*).
  * El programa traduce la pregunta en una consulta a InfluxDB.
  * Recupera los datos y los pasa al LLM.
  * El LLM devuelve un **resumen explicativo**.

---

### 4ï¸âƒ£ Resultados esperados

* Dashboard de Grafana mostrando grÃ¡ficas en tiempo real.
* Un chatbot (terminal o panel en Grafana) que responda:

  * "La temperatura promedio fue de 22Â°C y la mÃ¡xima de 29Â°C el jueves."
  * "Hubo una caÃ­da de humedad de 15% entre el lunes y miÃ©rcoles."

---

## ğŸ“š Entregables de la prÃ¡ctica

1. **Script de captura** (API â†’ InfluxDB).
2. **Dashboard en Grafana** con al menos 3 paneles.
3. **MÃ³dulo con API de LLM** que interprete preguntas en lenguaje natural.
4. **Informe final** explicando el flujo de datos y ejemplos de consultas/respuestas.

---

ğŸ‘‰ Con esta prÃ¡ctica, los estudiantes aplican:

* IntegraciÃ³n de APIs (OpenWeatherMAP).
* Manejo de series temporales (InfluxDB).
* Dashboards interactivos (Grafana).
* LLM aplicado como **intÃ©rprete de datos y asistente inteligente**.

---

## ANEXO: Ejemplo que debe mejorar 50% mas diferente.

```python
import requests
from datetime import datetime
from influxdb_client import InfluxDBClient, Point, WritePrecision
from openai import OpenAI

# ----------------------------
# CONFIGURACIÃ“N
# ----------------------------
# ğŸ”‘ API Key de OpenWeatherMap (poner la suya)
OPENWEATHER_API_KEY = "TU_API_KEY"
CITY = "Tijuana,mx"
URL = f"http://api.openweathermap.org/data/2.5/weather?q={CITY}&appid={OPENWEATHER_API_KEY}&units=metric"

# ğŸ”‘ ConfiguraciÃ³n InfluxDB
INFLUX_URL = "http://localhost:8086"
INFLUX_TOKEN = "TU_TOKEN_INFLUX"
INFLUX_ORG = "TU_ORG"
INFLUX_BUCKET = "clima"

# ğŸ”‘ ConfiguraciÃ³n LLM (ejemplo OpenAI GPT)
OPENAI_API_KEY = "TU_API_KEY_OPENAI"
client = OpenAI(api_key=OPENAI_API_KEY)

# ----------------------------
# 1. OBTENER DATOS DEL CLIMA
# ----------------------------
def obtener_clima():
    response = requests.get(URL)
    data = response.json()
    clima = {
        "temp": data["main"]["temp"],
        "humedad": data["main"]["humidity"],
        "viento": data["wind"]["speed"],
        "descripcion": data["weather"][0]["description"]
    }
    return clima

# ----------------------------
# 2. GUARDAR EN INFLUXDB
# ----------------------------
def guardar_in_influx(clima):
    with InfluxDBClient(url=INFLUX_URL, token=INFLUX_TOKEN, org=INFLUX_ORG) as clientdb:
        write_api = clientdb.write_api(write_options=None)

        point = (
            Point("clima")
            .tag("ciudad", CITY)
            .field("temperatura", clima["temp"])
            .field("humedad", clima["humedad"])
            .field("viento", clima["viento"])
            .time(datetime.utcnow(), WritePrecision.NS)
        )
        write_api.write(bucket=INFLUX_BUCKET, org=INFLUX_ORG, record=point)

# ----------------------------
# 3. CONSULTAR Y PREGUNTAR A LLM
# ----------------------------
def preguntar_llm(pregunta, datos):
    prompt = f"""
    Eres un asistente que analiza datos de clima.
    Datos disponibles: {datos}
    Pregunta del usuario: {pregunta}
    Responde en espaÃ±ol de forma clara y breve.
    """

    respuesta = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )

    return respuesta.choices[0].message.content

# ----------------------------
# MAIN
# ----------------------------
if __name__ == "__main__":
    # Paso 1: obtener datos
    clima = obtener_clima()
    print("Clima actual:", clima)

    # Paso 2: guardar en InfluxDB
    guardar_in_influx(clima)

    # Paso 3: ejemplo de consulta a LLM
    pregunta = "Â¿CÃ³mo estuvo la temperatura y humedad en esta lectura?"
    resumen = preguntar_llm(pregunta, clima)
    print("ğŸ¤– LLM responde:", resumen)

```
